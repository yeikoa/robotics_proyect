
# Sistema de Navegaci칩n y Control de Robot

Este proyecto permite controlar un robot usando comandos de voz, procesamiento de lenguaje natural y visi칩n por computadora. Con una interfaz sencilla en PyQt5, el usuario graba su voz, el sistema transcribe y entiende el mensaje, genera un plan de ruta hacia objetos detectados en una c치mara, y finalmente env칤a instrucciones f칤sicas al robot v칤a puerto serial.




## 游꿢 Caracter칤sticas

- Interfaz gr치fica para grabar comandos de voz
- Transcripci칩n autom치tica con Whisper
- Interpretaci칩n sem치ntica con Gemini (Google Generative AI)
- Comunicaci칩n con servidor Flask
- Traducci칩n autom치tica de objetivos con googletrans
- Detecci칩n de objetos y robot con YOLOv8
- Entrenamiento de modelo personalizado
- Planeaci칩n de rutas con algoritmo A*
- Control de robot v칤a puerto serial


## Screenshots
FALTA
![App Screenshot]()


## variables de entorno

Para iniciar este proyecto se necesita una llave de Google AI Studio, en .env.local se agrega esta.

`KEY_GEMINI` = "............."


## 游 Instalaci칩n
### Requisitos
- Python 3.8+
-  IP cam
- Arduino o microcontrolador conectado a puerto serial
### Instalaci칩n
```bash
#Clonar repositorio
 git clone https://github.com/yeikoa/robotics_proyect.git

# Instalar dependencias
pip install -r requirements.txt
```
## 丘뙖잺 Uso
-  Ejecutar la interfaz de control por voz
```bash
python ./voice_detector.py
```
- Iniciar servidor desde esta interfaz y grabar el comando de voz para que se env칤e a servidor
- Iniciar el codigo de python para la camara y capturar la ruta del robot y que se detecten los objetivos de este mediante IA
```bash
python ./camera.py
```
## 游Tecnolog칤as usadas
- Python
- PyQt5
- Whisper
- Google Generative AI
- YOLOv8
- Flask
- OpenCV
- googletrans
- Roboflow

## Autores

- [@yeikoa](https://www.github.com/yeikoa)
- [@AxelOreamuno](https://www.github.com/AxelOreamuno)

